# è®­ç»ƒå‚æ•°è®¾ç½®
## æ£€æŸ¥ç‚¹æ–‡ä»¶

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
| - | - | - | - |
| `run_name` | `str` | `xequinet` | è®­ç»ƒä»»åŠ¡çš„åç§°ï¼Œæ£€æŸ¥ç‚¹æ–‡ä»¶å°†ä»¥æ­¤å‘½å |
| `resume` | `bool` | `false` | æ˜¯å¦æ–­ç‚¹ç»­è®­ |
| `ckpt_file` | `str` | `null` | ç”¨äºè½½å…¥å‚æ•°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶å |
| `finetune_modules` | `list[str]` | `null` | å«æœ‰åˆ—è¡¨ä¸­å…³é”®è¯çš„æ¨¡å‹å‚æ•°æ‰ä¼šè¢«ä¼˜åŒ– |

### ç¤ºä¾‹ 1ï¼šæ–­ç‚¹ç»­è®­
```yaml
trainer:
  run_name: spice-v1
  ckpt_file: spice-v1_last.pt
  resume: true
```
è®­ç»ƒå¼€å§‹æ—¶ä¼šè¯»å– `spice-v1_last.pt` æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œè¯»å–æ¨¡å‹å‚æ•°çš„åŒæ—¶ï¼Œè¿˜ä¼šè¯»å– Epoch ä¿¡æ¯ï¼Œä¼˜åŒ–å™¨å‚æ•°å’Œå­¦ä¹ ç‡è°ƒæ•´å™¨çš„å‚æ•°ç­‰ã€‚æ¥ç€ä»æ£€æŸ¥ç‚¹æ–‡ä»¶æ–­å¼€çš„ Epoch å¼€å§‹ç»§ç»­è®­ç»ƒã€‚

### ç¤ºä¾‹ 2ï¼šå¾®è°ƒæ¨¡å‹
```yaml
trainer:
  run_name: spice-v2
  ckpt_file: spice-v1.pt
  resume: false
  finetune_modules: [output, embed]
  ...
```
è®­ç»ƒå¼€å§‹æ—¶å°†ä¼šè¯»å– `spice-v1.pt` æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œåªè½½å…¥å…¶ä¸­çš„æ¨¡å‹å‚æ•°ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä»…ä¼˜åŒ–åå­—ä¸­å¸¦æœ‰ `output` å’Œ `embed` çš„å‚æ•°ï¼ˆå¦‚ `module.mods.embedding.embedding.1.weight` å’Œ `module.mods.output_energy.out_mlp.0.weight` ç­‰ï¼‰ã€‚æ¥ç€ä»å¤´å¼€å§‹è®­ç»ƒã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„å‚æ•°å°†ä¼šå‘½åæˆ `spice_v2_0.pt` å’Œ `spice_v2_last.pt` ï¼Œå‰è€…æ˜¯éªŒè¯è¯¯å·®æœ€å¥½çš„æ¨¡å‹ï¼Œåè€…æ˜¯ä¸Šä¸€ä¸ª Epoch ç»“æŸæ—¶è‡ªåŠ¨ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¨¡å‹ã€‚

## æŸå¤±å‡½æ•°

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | å¯é€‰å‚æ•° |
| - | - | - | - | - |
| `lossfn` | `str` | `smoothl1` | æŸå¤±å‡½æ•°ç±»å‹ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰|  `mae`(`l1`), `mse`(`l2`), `smoothl1` |
| `losses_weight` | `dict[str, float]` | - | è¯¯å·®å‡½æ•°å„é¡¹ç»„åˆ†çš„æƒé‡ |

### æŸå¤±å‡½æ•°ç§ç±»
è¿™é‡Œå¯ä»¥ç”¨çš„æŸå¤±å‡½æ•°æœ‰ä¸‰ç§ï¼ŒL1 Lossã€L2 Loss å’Œ ä¸¤è€…å…¼å…·çš„ SmoothL1 Lossã€‚ä¸‰è€…çš„å‡½æ•°å½¢å¼å’Œå›¾åƒå¦‚ä¸‹ï¼ˆå›¾ä¸­ä¸ºäº†ç¾è§‚ç»™ L2 Loss ä¹˜äº†ä¸€ä¸ª 0.5 çš„ç³»æ•°ï¼‰ï¼š

![Loss](../figures/Loss.png)

- MAE Lossï¼Œå³ L1 Lossï¼š

$$
    l \left( \hat{y}, y \right) = \left| \hat{y} - y \right|
$$

- MSE Lossï¼Œå³ L2 Lossï¼š

$$
    l \left( \hat{y}, y \right) = \left( \hat{y} - y \right)^2
$$

- SmoothL1 Lossï¼š

$$
    l \left( \hat{y}, y \right) = \begin{cases}
        0.5 \left( \hat{y} - y \right)^2    & \left| \hat{y} - y \right| > 1 \\
        \left| \hat{y} - y \right| - 0.5 & \left| \hat{y} - y \right| \le 1 \\
    \end{cases}
$$

å¼ä¸­ $\hat{y}$ è¡¨ç¤ºçœŸå€¼ï¼Œ$y$ è¡¨ç¤ºé¢„æµ‹å€¼ã€‚

### æŸå¤±æƒé‡
`losses_weight` æ¥å—ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºç»™æŸå¤±å‡½æ•°çš„å„ç»„åˆ†åˆ†é…ä¸€ä¸ªæƒé‡ã€‚æ¯”è¾ƒå¸¸è§çš„æƒ…å†µæ—¶è®­ç»ƒåŠ›åœºæ¨¡å‹æ—¶åŒæ—¶ç›‘ç£èƒ½é‡å’ŒåŠ›ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½é‡å’ŒåŠ›è¯¯å·®çš„æƒé‡æ¯”æ—¶ 1:1000ï¼Œå°±å¯ä»¥è¿™æ ·è®¾ç½®ï¼š
```yaml
trainer:
  ...
  lossfn: smoothl1
  losses_weight:
      energy: 1.0
      forces: 1000.0
  ...
```
è¿™æ ·å°±ä»£è¡¨ç€æ€»æŸå¤± $\mathcal{L} = 1 \times l \left( \hat{E}, E \right) + 1000 \times l \left( \hat{\mathbf{F}}, \mathbf{F} \right)$ã€‚

å½“ç„¶ `energy` å’Œ `forces` é¡»åœ¨æ•°æ®å‚æ•°çš„ `target` æ ä¸­å£°æ˜ï¼Œè¿™æ ·ç¨‹åºæ‰ä¼šä»æ•°æ®é›†ä¸­è¯»å–ç›¸åº”çš„æ ‡ç­¾ç”¨äºæŸå¤±è®¡ç®—ã€‚

## ä¼˜åŒ–å™¨
| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | å¯é€‰å‚æ•° |
| - | - | - | - | - |
| `optimizer` | `str` | `AdamW` | ä¼˜åŒ–å™¨ç±»å‹ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰| `Adam`, `AdamW`, `NAdam`, `RAdam` |
| `optimizer_kwargs` | `dict` | `{}` | ä¼ ç»™ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œå¯è§ [torch.optim](https://pytorch.org/docs/stable/optim.html#algorithms) | |

### ä¼˜åŒ–å™¨ç§ç±»
Adam å®‡å®™äº†è¯´æ˜¯ã€‚
- `Adam`ï¼šé€šå¸¸æ¥è¯´ Adam ä½œä¸ºé€šç”¨é¦–é€‰åº”è¯¥æ˜¯æ²¡ä»€ä¹ˆé—®é¢˜äº†ï¼Œé€‚åº”å¤§å¤šæ•°ä»»åŠ¡
- `AdamW`ï¼šå°±æ˜¯åŠ äº† Weight Decay çš„ Adamï¼Œç›¸æ¯”ä¹‹ä¸‹**ä¿®æ­£äº†æƒé‡è¡°å‡çš„å®ç°æ–¹å¼**ï¼Œå› æ­¤éœ€è¦åŠ æƒé‡è¡°å‡çš„æ—¶å€™è®°å¾—ä½¿ç”¨ AdamW
- `NAdam`ï¼šåœ¨ Adam åŸºç¡€ä¸Šèåˆ Nesterov åŠ¨é‡ï¼Œé€‚ç”¨äºéœ€è¦å¿«é€Ÿæ”¶æ•›çš„ä»»åŠ¡ï¼ˆå¦‚å°æ•°æ®é›†è®­ç»ƒï¼‰ã€‚
- `RAdam`ï¼šåœ¨è®­ç»ƒåˆæœŸå¯¹è‡ªé€‚åº”å­¦ä¹ ç‡è¿›è¡Œæ–¹å·®ä¿®æ­£ï¼Œé€‚åˆè®­ç»ƒåˆæœŸéœ€è¦ç¨³å®šçš„ä»»åŠ¡ï¼ˆå¦‚å°æ‰¹é‡æ•°æ®ï¼‰ã€‚

### ç¤ºä¾‹
```yaml
trainer:
  ...
  optimizer: AdamW
  optimizer_kwargs:
    betas: [0.9, 0.999]
    weight_decay: 0.01
  ...
```
è¿™æ ·è®¾ç½®çš„è¯ï¼Œå°±ä¼šä½¿ç”¨ `AdamW` ä¼˜åŒ–å™¨ï¼Œå‚æ•°è®¾ç½®ä¸Š `betas=(0.9, 0.99)`ã€`weight_decay=0.1`ï¼ˆYAML æ–‡ä»¶æ²¡æœ‰ Tupleï¼Œè¿™é‡Œæ‰€å¹¸ä¼  List è¿› Optimizer ä¹Ÿèƒ½è·‘ï¼‰

## å­¦ä¹ ç‡

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
| - | - | - | - |
| `max_lr` | `float` | `5e-4` | å­¦ä¹ ç‡æœ€å¤§å€¼ |
| `min_lr` | `float` | `0.0` | å­¦ä¹ ç‡æœ€å°å€¼ |

å­¦ä¹ ç‡å˜åŒ–çš„ä¸Šé™å’Œä¸‹é™ï¼Œåœ¨ä¸åŒçš„å­¦ä¹ ç‡è°ƒæ•´å™¨ä¸‹å«ä¹‰å„ä¸ç›¸åŒã€‚

## å­¦ä¹ ç‡é¢„çƒ­

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | å¯é€‰å‚æ•° |
| - | - | - | - | - |
| `warmup_scheduler` | `str` | `linear` | å­¦ä¹ ç‡é¢„çƒ­æ–¹å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ | `null`, `linear`, `exponential`, `untuned_linear`, `untuned_exponential`, `RAdam` |
| `warmup_epochs` | `int` | `10` | å­¦ä¹ ç‡é¢„çƒ­ Epoch æ•° | - |

å­¦ä¹ ç‡é¢„çƒ­æ˜¯ä½¿ç”¨çš„ [pytorch-warmup](https://pypi.org/project/pytorch-warmup/) åº“ï¼Œç®€å•æ¥è¯´å°±æ˜¯å°†å­¦ä¹ ç‡ç¼“ç¼“ä» 0 å¼€å§‹ä¸Šå‡ï¼Œé¿å…åˆå§‹å­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚`warmup_epochs` ä»…é’ˆå¯¹ `linear` å’Œ `exponential` ç”Ÿæ•ˆï¼Œç¨‹åºä¼šå°†é¢„çƒ­çš„ Epoch æ•°é‡æ¢ç®—æˆæ¢¯åº¦ä¸‹é™çš„æ­¥æ•°ã€‚ä»¥ä½™å¼¦å­¦ä¹ ç‡å˜åŒ–ä¸ºä¾‹ï¼Œä¸‹å›¾ä¸º 2500 æ­¥ï¼ˆä¸æ˜¯ Epochï¼‰é¢„çƒ­çš„å­¦ä¹ ç‡å˜åŒ–å›¾ï¼š

![Warmup](../figures/Warmup.png)

ç›¸å½“äºåœ¨å­¦ä¹ ç‡ä¸Š $\eta_t$ ä¹˜ä¸Šä¸€ä¸ªé¢„çƒ­ç³»æ•° $\omega_t \in \left[ 0, 1 \right]$ï¼Œå³

$$
    \hat{\eta}_t = \eta_t \cdot \omega_t
$$

### çº¿æ€§é¢„çƒ­
çº¿æ€§é¢„çƒ­åˆ†ä¸¤ç§ï¼Œæ‰‹åŠ¨è®¾ç½®é¢„çƒ­æ­¥æ•°çš„ `linear` å’Œè‡ªåŠ¨æ ¹æ® Adam ç±»ä¼˜åŒ–å™¨çš„ $\beta_2$ å€¼è®¾å®šé¢„çƒ­æ­¥æ•°çš„ `untuned_linear`ã€‚å…¶é¢„çƒ­ç³»æ•°ä¸ºï¼š

$$
    \omega_t = \min \left( 1, \frac{t}{\tau} \right)
$$

å…¶ä¸­ï¼Œ$t$ ä¸ºå½“å‰æ­¥æ•°ï¼Œ$\tau$ ä¸ºé¢„çƒ­æ­¥æ•°ï¼Œå¯¹äº `untuned_linear`ï¼Œ$\tau = \lfloor \frac{2}{1-\beta_2} \rfloor$

### æŒ‡æ•°é¢„çƒ­
æŒ‡æ•°é¢„çƒ­åŒæ ·åˆ†ä¸¤ç§ï¼Œé¢„çƒ­ç³»æ•°ä¸ºï¼ˆè¿™é‡Œå’Œå®˜æ–¹ä¸ä¸€æ ·ï¼Œå®˜æ–¹è¿™é‡Œæ²¡æœ‰ 2ï¼Œæˆ‘è¿™é‡Œæ˜¯ä¸ºäº†å’Œ `untuned_exponential` ä¿æŒä¸€è‡´ï¼‰ï¼š

$$
    \omega_t = 1 - \exp \left( -\frac{2t}{\tau} \right)
$$

åŒæ ·ï¼Œ$t$ ä¸ºå½“å‰æ­¥æ•°ï¼Œ$\tau$ ä¸ºé¢„çƒ­æ­¥æ•°ï¼Œå¯¹äº `untuned_exponential`ï¼Œ$\tau = \lfloor \frac{2}{1-\beta_2} \rfloor$

### RAdam é¢„çƒ­
è¿™ä¸ªæœ‰ç‚¹å¤æ‚ï¼Œæ‡’å¾—å†™äº†ï¼Œçœ‹[å®˜æ–¹è§£é‡Š](https://tony-y.github.io/pytorch_warmup/v0.2.0/radam_warmup.html)å§ğŸ¤­


## å­¦ä¹ ç‡è°ƒæ•´å™¨

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | å¯é€‰å‚æ•° |
| - | - | - | - | - |
| `lr_scheduler` | `str` | `cosine_annealing` | å­¦ä¹ ç‡è°ƒæ•´æ–¹å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ | `cosine_annealing`(`cosine`), `cosine_annealing_warm_restarts`<br>(`cosine_restarts`), `reduce_on_plateau`(`plateau`) |
| `lr_scheduler_kwargs` | `dict` | `{}` | ä¼ ç»™å­¦ä¹ ç‡è°ƒæ•´å™¨çš„å‚æ•° | - |

### ä½™å¼¦é€€ç«
å­¦ä¹ ç‡æŒ‰ä½™å¼¦å‡½æ•°å‘¨æœŸæ€§è°ƒæ•´ï¼Œå½“å‰ç¬¬ $t$ æ­¥çš„å­¦ä¹ ç‡ $\eta_t$ ä¸ºï¼š

$$
    \eta_t = \eta_{\min} + \frac{1}{2} \left( \eta_{\max} - \eta_{\min} \right) \left( 1 + \cos{\frac{t}{T_{\max}} \pi} \right)
$$

å¼ä¸­ $\eta_{\min}$ å’Œ $\eta_{\max}$ åˆ†åˆ«è¡¨ç¤ºæœ€å°å’Œæœ€å¤§å­¦ä¹ ç‡ï¼Œ$T_{\max}$ è¡¨ç¤ºä½™å¼¦å‡½æ•°å˜åŒ–çš„åŠå‘¨æœŸï¼Œå­¦ä¹ ç‡å˜åŒ–æƒ…å†µå¦‚å›¾æ‰€ç¤ºï¼š

![CosineAnnealing](../figures/CosineAnnealing.png)

å°½ç®¡ä¸Šè¿°å…¬å¼å’Œå›¾åƒä¸­ `T_max` è¡¨ç¤ºåŠå‘¨æœŸçš„**æ­¥æ•°**ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸€èˆ¬æ›´æƒ³æ ¹æ® Epoch æ•°è°ƒæ•´ï¼Œå› æ­¤å‚æ•°è®¾ç½®æ—¶ `T_max` æŒ‡çš„æ˜¯åŠå‘¨æœŸ **Epoch æ•°**ï¼Œç¨‹åºä¼šè‡ªåŠ¨è°ƒæ•´ä¸ºæ­¥æ•°ä¼ ç»™å­¦ä¹ ç‡è°ƒæ•´å™¨ã€‚

```yaml
trainer:
  ...
  max_lr: 1e-3
  min_lr: 0.0
  lr_scheduler: cosine_annealing  # cosine
  lr_scheduler_kwargs:
    T_max: 300
  ...
```

ä¸Šè¿°ç¤ºä¾‹å³ä¸ºåŠå‘¨æœŸä¸º 300 **Epochs** çš„ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒæ•´å™¨ï¼Œå­¦ä¹ ç‡å˜åŒ–çš„èŒƒå›´ä¸º 0.0 åˆ° 1e-3ã€‚

ä»ä½¿ç”¨ä½“éªŒä¸Šæ¥è¯´ï¼Œä½™å¼¦é€€ç«å­¦ä¹ ç‡æ•ˆæœè¿˜æ˜¯æ¯”è¾ƒç¨³å®šçš„ï¼Œç”¨èµ·æ¥ä¹Ÿæ¯”è¾ƒçœå¿ƒã€‚

### ä½™å¼¦é€€ç«çƒ­é‡å¯
ä¸ä½™å¼¦é€€ç«ä¸åŒï¼Œä½™å¼¦é€€ç«å†·é‡å¯åˆ°è°·åº•æ—¶æ˜¯æ…¢æ…¢å›å‡åˆ°å­¦ä¹ ç‡æœ€å¤§å€¼ï¼Œè€Œçƒ­é‡å¯åˆ°è°·åº•æ—¶ä¼šç«‹åˆ»å›åˆ°æœ€å¤§å­¦ä¹ ç‡ã€‚

$$
    \eta_t = \eta_{\min} + \frac{1}{2} \left( \eta_{\max} - \eta_{\min} \right) \left( 1 + \cos{\frac{t - T_k}{T_{k+1} - T_k} \pi} \right) \quad T_k \le t < T_{k+1}
$$

ä½†æ˜¯æ¯æ¬¡ä½™å¼¦ä¸‹é™çš„åŠå‘¨æœŸéƒ½ä¼šå˜ä¸ºåŸå…ˆçš„ $\mu$ å€ï¼Œå³ $T_{k+1} - T_k = \mu^k \tau$ï¼Œ$\tau$ ä¸ºåˆå§‹åŠå‘¨æœŸã€‚æ›´ç›´è§‚çš„å­¦ä¹ ç‡å˜åŒ–å›¾å¦‚å›¾æ‰€ç¤ºï¼š

![CosineAnnealingWarmRestarts](../figures/CosineAnnealingWarmRestarts.png)

ä½¿ç”¨æ–¹æ³•ä¸º:

```yaml
trainer:
  ...
  max_lr: 1e-3
  min_lr: 0.0
  lr_scheduler: cosine_restarts  # cosine_annealing_warm_restarts
  lr_scheduler_kwargs:
    T_0: 50
    T_mult: 2
  ...
```
è¿™é‡Œ `T_0` æŒ‡åˆå§‹åŠå‘¨æœŸ **Epoch æ•°**ï¼Œç¨‹åºä¹ŸåŒæ ·ä¼šè‡ªåŠ¨è°ƒæ•´ä¸ºæ­¥æ•°ï¼Œ`T_mult` æŒ‡çš„æ˜¯ï¼Œæ¯æ¬¡é‡å¯ä¹‹ååŠå‘¨æœŸå€¼éƒ½ä¼šä¹˜ä»¥è¿™ä¸ªæ•°ï¼Œè¿™é‡Œè®¾ç½®æˆ 2ï¼Œæ„æ€æ˜¯æ¯æ¬¡é‡å¯ï¼ŒåŠå‘¨æœŸéƒ½å˜ä¸ºåŸæ¥çš„ä¸¤å€ã€‚


### å­¦ä¹ ç‡å¹³å°è¡°å‡
å½“éªŒè¯é›†è¯¯å·®è¿ç»­è‹¥å¹² Epoch æœªæ”¹å–„æ—¶ï¼Œå°†å­¦ä¹ ç‡é™ä½ï¼Œç›´åˆ°å­¦ä¹ ç‡å°äºé¢„è®¾çš„æœ€å°å­¦ä¹ ç‡æ—¶ç»“æŸè®­ç»ƒã€‚ç›´æ¥ä¸¾ä¾‹è¯´æ˜ï¼š

```yaml
trainer:
  ...
  max_lr: 1e-3
  min_lr: 1e-6
  lr_scheduler: reduce_on_plateau  # plateau
  lr_scheduler_kwargs:
    factor: 0.5
    patience: 50
  ...
  ```
æ„æ€æ˜¯å­¦ä¹ ç‡ä» 1e-3 å¼€å§‹ï¼Œå¦‚æœè¿ç»­ 50 ä¸ª Epoch éªŒè¯é›†è¯¯å·®æ²¡æœ‰æ”¹å–„ï¼Œå°±å°†å­¦ä¹ ç‡ä¹˜ä»¥ 0.5ï¼Œç›´åˆ°å­¦ä¹ ç‡å°äº 1e-6 åœæ­¢è®­ç»ƒã€‚


## å…¶ä»–å‚æ•°

| å…³é”®è¯ | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
| - | - | - | - |
| `max_epochs` | `int` | `300` | æœ€å¤§è®­ç»ƒ Epoch æ•°é‡ |
| `grad_clip` | `float` | `null` | æ¢¯åº¦è£å‰ªæ•°å€¼ï¼Œç¡®ä¿å‚æ•°æ¢¯åº¦çš„èŒƒæ•°ä¸è¶…è¿‡è¯¥è®¾å®šå€¼ |
| 